{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def init_setup():\n",
    "    # initiate the dataset for the algorithm\n",
    "    idx = 2\n",
    "    print(\"loading data\")\n",
    "    # load the data\n",
    "    samples = save_and_load_list(2, \"cumulants_vec\", idx)\n",
    "    samples_dx = save_and_load_list(2, \"cum_dx_vec\", idx)\n",
    "    sample_real = save_and_load_list(2, \"cum_real_vec\", idx)\n",
    "    sample_imag = save_and_load_list(2, \"cum_imag_vec\", idx)\n",
    "    labels = save_and_load_list(2, \"labels\", idx)\n",
    "    snr = save_and_load_list(2, \"snr_vec\", idx)\n",
    "    # dataset = save_and_load_list(2, \"dataset\", idx)\n",
    "    dataset = {'samples': samples, 'dx': samples_dx, 'real': sample_real, 'imag': sample_imag, \n",
    "                'label': labels, 'snr':snr}\n",
    "    print('finished')\n",
    "    return dataset\n",
    "\n",
    "def save_and_load_list(variable, name, case):\n",
    "    # save and load using pickle based on what to do (case)\n",
    "    # case 1 for save my_list\n",
    "    # case 2 for load file\n",
    "    path = \"data/\"\n",
    "    if case == 1:\n",
    "        with open(path + name + \".pkl\", \"wb\") as f:\n",
    "            pickle.dump(variable, f)\n",
    "    if case == 2:\n",
    "        with open(path + name + \".pkl\", \"rb\") as f:\n",
    "            load_variable = pickle.load(f)\n",
    "        return load_variable\n",
    "    \n",
    "def prep_data(dataset):\n",
    "    # get the data ready for classification\n",
    "    dataset_prep = {}\n",
    "    dataset_prep['label'] = np.array(dataset['label'])\n",
    "    dataset_prep['snr'] = np.array(dataset['snr'])\n",
    "    dataset_prep['data']=cumulant_fix(dataset['samples'],dataset['dx'],dataset['real'],dataset['imag'])\n",
    "    return dataset_prep\n",
    "\n",
    "def cumulant_fix(cum,dx,I,Q):\n",
    "    features_vec = []\n",
    "    for ii in range(len(cum)):\n",
    "        cum_abs = abs(cum[ii])\n",
    "        dx_abs = abs(dx[ii])\n",
    "        abs_I = abs(I[ii])\n",
    "        abs_Q = abs(Q[ii])\n",
    "        feats = []\n",
    "        for jj in range(2,len(cum_abs)):\n",
    "            feats.append(np.log10(cum_abs[jj]/cum_abs[1]))\n",
    "        for jj in [2,3,4,5,6]:\n",
    "            feats.append(np.log10(dx_abs[jj]))\n",
    "        for jj in range(1,len(abs_I)):\n",
    "            feats.append(np.log10(abs_I[jj]*0.5 + abs_Q[jj]*0.5))\n",
    "        features_vec.append(feats) \n",
    "    \n",
    "    return np.array(features_vec)\n",
    "\n",
    "def start_amc():\n",
    "    # get the data preprocessed\n",
    "    dataset = init_setup()\n",
    "    dataset_prep = prep_data(dataset)\n",
    "    easy_mods = [\n",
    "        \"OOK\",\n",
    "        \"4ASK\",\n",
    "        \"BPSK\",\n",
    "        \"QPSK\",\n",
    "        \"8PSK\",\n",
    "        \"16QAM\",\n",
    "        \"AM-SSB-SC\",\n",
    "        \"AM-DSB-SC\",\n",
    "        \"FM\",\n",
    "        \"GMSK\",\n",
    "        \"OQPSK\",\n",
    "    ]\n",
    "    easy_mask = np.isin(dataset_prep['label'], easy_mods)\n",
    "    labels = dataset_prep['label'][easy_mask]\n",
    "    snr = dataset_prep['snr'][easy_mask]\n",
    "    samples = dataset_prep['data'][easy_mask]\n",
    "\n",
    "    return samples,labels,snr\n",
    "\n",
    "def init_classification(samples, labels, snr, name, train_tresh, tree_depth):\n",
    "    # get the accuracy graph per SNR and per label\n",
    "    labeling = f\"train_from_{train_tresh}_SNR_{name}\"\n",
    "    x_train, x_test, y_train, y_test,snr_test = data_spliting(samples, labels, snr, train_tresh)\n",
    "    classifier = DecisionTreeClassifier(max_depth=tree_depth)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    # print(classifier.get_depth())\n",
    "    try:\n",
    "        os.mkdir(labeling)\n",
    "    except FileExistsError:\n",
    "        print('skip creation')\n",
    "    print(\"Classify per SNR\")\n",
    "    accuracy_data = detection_per_snr(x_test, y_test, snr_test, classifier, labeling)\n",
    "    # accuracy_data =1\n",
    "    print(\"Classify per Label\")\n",
    "    detection_per_label(x_test, y_test, snr_test, classifier, labeling)\n",
    "    \n",
    "    return accuracy_data,classifier\n",
    "\n",
    "def data_spliting(samples, labels ,snr , train_tresh):\n",
    "    # split data for training using only high SNR\n",
    "    if train_tresh>0:\n",
    "        mask = snr>train_tresh\n",
    "        samples_mask = samples[mask]\n",
    "        labels_mask = labels[mask]\n",
    "        snr_mask = snr[mask]\n",
    "        samples_not = samples[~mask]\n",
    "        labels_not = labels[~mask]\n",
    "        x_train, x_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        samples_mask,\n",
    "        labels_mask,\n",
    "        range(len(samples_mask)),\n",
    "        test_size=0.3,\n",
    "        random_state=42,\n",
    "        stratify=labels_mask,\n",
    "    )\n",
    "        x_test=np.concatenate((x_test,samples_not))\n",
    "        y_test=np.concatenate((y_test,labels_not))\n",
    "        snr_test = np.concatenate((snr_mask[test_indices],snr[~mask]))\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        samples,\n",
    "        labels,\n",
    "        range(len(samples)),\n",
    "        test_size=0.33,\n",
    "        random_state=42,\n",
    "        stratify=labels,\n",
    "    )\n",
    "        snr_test = snr[test_indices]\n",
    "    return x_train, x_test, y_train, y_test,snr_test\n",
    "\n",
    "def detection_per_snr(x_test, y_test, snr_test, classifier, name):\n",
    "    # classification per SNR\n",
    "    unique_snr = np.unique(snr_test)\n",
    "    accuracy_list = []\n",
    "    for snr_val in unique_snr:\n",
    "        mask = snr_test == snr_val\n",
    "        x_snr = x_test[mask]\n",
    "        y_snr = y_test[mask]\n",
    "        y_pred_snr = classifier.predict(x_snr)\n",
    "        accuracy_snr = accuracy_score(y_snr, y_pred_snr)\n",
    "        accuracy_list.append(accuracy_snr)\n",
    "        if snr_val in range(11):\n",
    "            plot_confusion_matrix(y_snr, y_pred_snr, np.unique(y_snr), snr_val, name)\n",
    "    return {\"snr\": unique_snr, \"accuracy\": accuracy_list, \"name\": name}\n",
    "\n",
    "def detection_per_label(x_test, y_test, snr_test, classifier, name):\n",
    "    # classify per label\n",
    "    unique_snr = np.unique(snr_test)\n",
    "    unique_label = np.unique(y_test)\n",
    "    i=1\n",
    "    num_plots = i  # Number of plots needed\n",
    "    fig, axs = plt.subplots(nrows=num_plots, ncols=1, figsize=(10, 6 * num_plots))\n",
    "    axs.set_title(f\"Accuracy vs SNR\")\n",
    "    for label in unique_label:\n",
    "        if label =='others':\n",
    "            continue\n",
    "        mask = y_test == label\n",
    "        x_label = x_test[mask]\n",
    "        y_label = y_test[mask]\n",
    "        snr_label = snr_test[mask]\n",
    "        accuracy_list = []\n",
    "        for snr_val in unique_snr:\n",
    "            mask_snr = snr_label == snr_val\n",
    "            x_snr = x_label[mask_snr]\n",
    "            y_snr = y_label[mask_snr]\n",
    "            y_pred_snr = classifier.predict(x_snr)\n",
    "            accuracy_snr = accuracy_score(y_snr, y_pred_snr)\n",
    "            accuracy_list.append(accuracy_snr)\n",
    "        axs.plot(unique_snr, accuracy_list, label=label)\n",
    "    axs.set_xlabel(\"SNR\")\n",
    "    axs.set_ylabel(\"Accuracy\")\n",
    "    axs.legend()\n",
    "    axs.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    axs.xaxis.set_major_locator(MultipleLocator(2))\n",
    "    axs.grid(which='major')\n",
    "    plt.tight_layout()\n",
    "    file_path = os.path.join(name, f\"label_group_accuracy_{name}.png\")\n",
    "    plt.savefig(file_path)\n",
    "    print(\"saved plots\")\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "def detection_per_label_old(x_test, y_test, snr_test, name,classifier1,classifier2,classifier3):\n",
    "    group1 = ['AM-DSB-SC','AM-SSB-SC','FM','GMSK','OQPSK']\n",
    "    group2 = ['OOK','4ASK','BPSK','QPSK','8PSK','16QAM']\n",
    "    groups = [group1, group2]   \n",
    "    # classify per label\n",
    "    unique_snr = np.unique(snr_test)\n",
    "    num_plots = len(groups)  # Number of plots needed\n",
    "    fig, axs = plt.subplots(nrows=num_plots, ncols=1, figsize=(10, 6 * num_plots))\n",
    "    for i, label_group in enumerate(groups):\n",
    "        axs[i].set_title(f\"Accuracy vs SNR for Label Group {i+1}\")\n",
    "        for label in label_group:\n",
    "            mask = y_test == label\n",
    "            x_label = x_test[mask]\n",
    "            y_label = y_test[mask]\n",
    "            snr_label = snr_test[mask]\n",
    "            accuracy_list = []\n",
    "            for snr_val in unique_snr:\n",
    "                mask_snr = snr_label == snr_val\n",
    "                x_snr = x_label[mask_snr]\n",
    "                y_snr = y_label[mask_snr]\n",
    "                try:\n",
    "                    y_pred_snr = steps_tree(x_snr,classifier1,classifier2,classifier3)\n",
    "                except:\n",
    "                    print('help')\n",
    "                accuracy_snr = accuracy_score(y_snr, y_pred_snr)\n",
    "                accuracy_list.append(accuracy_snr)\n",
    "            axs[i].plot(unique_snr, accuracy_list, label=label)\n",
    "        axs[i].set_xlabel(\"SNR\")\n",
    "        axs[i].set_ylabel(\"Accuracy\")\n",
    "        axs[i].legend()\n",
    "        axs[i].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        axs[i].xaxis.set_major_locator(MultipleLocator(2))\n",
    "        axs[i].grid(which='major')\n",
    "    plt.tight_layout()\n",
    "    file_path =  f\"label_group_accuracy_{name}.png\"\n",
    "    plt.savefig(file_path)\n",
    "    print(\"saved plots\")\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "def plot_confusion_matrix(y_true, y_pred, labels, snr, name):\n",
    "    # plot confusion matrix for the data\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(f\"Confusion Matrix for SNR={snr}dB, Acc={accuracy}%\")\n",
    "    file_path = os.path.join(name, f\"SNR={snr}.png\")\n",
    "    plt.savefig(file_path)\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "def split_classification(samples,labels,snr,feats,name,group):\n",
    "    \n",
    "    mask = np.isin(labels,group)\n",
    "    labels_temp = labels.copy()\n",
    "    if group:\n",
    "        labels_temp[~mask]='others'\n",
    "    samples_fix = samples[:,feats]\n",
    "    train_tresh = 1\n",
    "    tree_depth = 4\n",
    "    accuracy_data,classifier = init_classification(samples_fix, labels_temp, snr, name, train_tresh, tree_depth)\n",
    "    return classifier,mask\n",
    "\n",
    "def combine_accuracy_graphs(*args):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    for accuracy_data in args:\n",
    "        ax.plot(accuracy_data[\"snr\"], accuracy_data[\"accuracy\"], label=accuracy_data[\"name\"])\n",
    "    ax.set_xlabel(\"SNR\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(\"Accuracy vs SNR\")\n",
    "    ax.legend()\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(2))\n",
    "    ax.grid(which='major')\n",
    "    num_files_saved = sum(1 for file in os.listdir('.') if file.startswith('combine_accuracy_graph_'))\n",
    "    file_path = f'combine_accuracy_graph_{num_files_saved + 1}.png'\n",
    "    plt.savefig(file_path)\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "def steps_tree(X,classifier1,classifier2,classifier3):\n",
    "# Step 1: Initial classification into 4 labels, one of them is \"others\"\n",
    "    labels_step1 = classifier1.predict(X)\n",
    "\n",
    "    # Step 2: Identify \"others\" samples from Step 1 and classify them into 4 labels, one of them is \"others\"\n",
    "    X_others_step2 = X[labels_step1 == \"others\"]\n",
    "    if len(X_others_step2)>0:\n",
    "        labels_step2 = classifier2.predict(X_others_step2)\n",
    "        X_others_step3 = X_others_step2[labels_step2 == \"others\"]\n",
    "        if len(X_others_step3)>0:     \n",
    "            labels_step3 = classifier3.predict(X_others_step3)\n",
    "        else:\n",
    "            labels_step3 = 'good'\n",
    "    else:\n",
    "        labels_step2='good'\n",
    "        labels_step3 = 'good'\n",
    "\n",
    "    # Step 3: Identify \"others\" samples from Step 2 and classify them into 5 labels\n",
    "            \n",
    "\n",
    "    # Combine the labels from Steps 1, 2, and 3 into the final labels\n",
    "    final_labels = []\n",
    "    current_index_step2 = 0\n",
    "    current_index_step3 = 0\n",
    "\n",
    "    for label in labels_step1:\n",
    "        if label == \"others\":\n",
    "            if labels_step2[current_index_step2] == \"others\":\n",
    "                final_labels.append(labels_step3[current_index_step3])\n",
    "                current_index_step3 += 1\n",
    "            else:\n",
    "                final_labels.append(labels_step2[current_index_step2])\n",
    "            current_index_step2 += 1\n",
    "        else:\n",
    "            final_labels.append(label)\n",
    "\n",
    "    # Now 'final_labels' contains the final classification of all samples\n",
    "\n",
    "    # Now 'final_labels' contains the final classification of all samples\n",
    "    return final_labels\n",
    "\n",
    "def step_by_step(samples,labels,snr):\n",
    "    \n",
    "    all_feats = [i for i in range(len(samples[1]))]\n",
    "\n",
    "    split1 = ['AM-SSB-SC','4ASK','BPSK']\n",
    "    classifier1,mask1 = split_classification(samples,labels,snr,all_feats,'split_1',split1)\n",
    "\n",
    "    temp_labels = labels[~mask1]\n",
    "    samples2 = samples[~mask1]\n",
    "    snr_temp = snr[~mask1]\n",
    "    split2 = ['AM-DSB-SC','FM','OOK']\n",
    "    classifier2,mask2 = split_classification(samples2,temp_labels,snr_temp,all_feats,'split_2',split2)\n",
    "\n",
    "    temp_labels = labels[~mask1][~mask2]\n",
    "    samples3 = samples2[~mask2]\n",
    "    snr_temp = snr_temp[~mask2]\n",
    "    split3 = ['16QAM','8PSK','GMSK','QPSK','OQPSK']\n",
    "    classifier3,mask3 = split_classification(samples3,temp_labels,snr_temp,all_feats,'split_3',split3)\n",
    "    \n",
    "    detection_per_label_old(samples, labels, snr, 'full split',classifier1,classifier2,classifier3)\n",
    "    # classification per SNR\n",
    "    unique_snr = np.unique(snr)\n",
    "    unique_labels = np.unique(labels)\n",
    "    accuracy_list = []\n",
    "    for snr_val in unique_snr:\n",
    "        mask = snr == snr_val\n",
    "        x_snr = samples[mask]\n",
    "        y_snr = labels[mask]\n",
    "        final_labels = steps_tree(x_snr,classifier1,classifier2,classifier3)\n",
    "        accuracy_snr = accuracy_score(y_snr, final_labels)\n",
    "        accuracy_list.append(accuracy_snr)\n",
    "        if snr_val in range(11):\n",
    "            cm = confusion_matrix(y_snr, final_labels, labels=unique_labels)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=unique_labels, yticklabels=unique_labels)\n",
    "            plt.xlabel(\"Predicted Labels\")\n",
    "            plt.ylabel(\"True Labels\")\n",
    "            plt.title(f\"Confusion Matrix for SNR={snr_val}dB, Acc={accuracy_snr}%\")\n",
    "            file_path = f\"confusion_matrix_SNR={snr_val}.png\"\n",
    "            plt.savefig(file_path)\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "    accuracy_steps  = {\"snr\": unique_snr, \"accuracy\": accuracy_list, \"name\": 'Steps Classification'}\n",
    "    return accuracy_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples,labels,snr = start_amc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"we are here\")\n",
    "train_tresh = 1\n",
    "# samples_fix = samples[:,feats]\n",
    "# regular tree classifiers\n",
    "print(\"classification for cumulants...\")\n",
    "accuracy_data0,classifier = init_classification(samples[:,range(6)], labels, snr, \"cumulants\", 1, 6)\n",
    "accuracy_data1,classifier = init_classification(samples[:,range(10)], labels, snr, \"cumulants_and_dx\", 1, 6)\n",
    "accuracy_data2,classifier = init_classification(samples, labels, snr, \"cumulants_with_dx_IQ\", 1, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy_steps = step_by_step(samples,labels,snr)\n",
    "combine_accuracy_graphs(accuracy_data0,accuracy_data1,accuracy_data2,accuracy_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DNN classifier\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# model.add(layers.Dense(8, activation='relu'))\n",
    "# model.add(layers.Dense(np.unique(y_train).shape[0], activation='softmax'))\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=1, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # SVM classifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# svm_classifier = SVC(kernel='linear', C=1.0)  # You can use other kernels as well\n",
    "# print('fitting')\n",
    "# svm_classifier.fit(X_train, y_train)\n",
    "# print('predict')\n",
    "# y_pred = svm_classifier.predict(X_test)\n",
    "# # Calculate the accuracy of the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
