{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "from algorithm_module import start_amc, init_classification, combine_accuracy_graphs, combo_graph\n",
    "\n",
    "samples, labels, snr, feature_list = start_amc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results for the main classifier\n",
    "\n",
    "# x_train, x_test, y_train, y_test, snr_test = threshold_split(samples,labels,snr)\n",
    "# Groups = [\n",
    "#         ['AM-SSB-SC'], # group 0\n",
    "#         ['AM-DSB-SC','BPSK'],# group 1\n",
    "#         ['4ASK','OOK'],# group 2\n",
    "#         ['GMSK','FM'],# group 3\n",
    "#         ['16QAM','8PSK','QPSK','OQPSK']] # group 4\n",
    "\n",
    "\n",
    "# feat_pick = [[7],[6,0,5,8,4],[1,6,0],[3,0,7,4],[2,4,11,12,13,10,8,9,7]]\n",
    "# # feat_pick = [[7,2,4],[1,0,6],[3,0,4],[2,11,13]]\n",
    "\n",
    "# depth = [1,4,2,2,2]\n",
    "\n",
    "# proxy_depth = np.ceil(100*np.log2(np.sum(pow(2,np.array(depth))-1)))/100\n",
    "# total_depth = int(np.ceil(proxy_depth))\n",
    "\n",
    "\n",
    "# full_classifier = SequentialClassifier(Groups,feat_pick)\n",
    "\n",
    "# # full_classifier.add_classifier(DecisionTreeClassifier(max_depth=depth[0]))\n",
    "# # full_classifier.add_classifier(DoubleClassifier(depth[1],Groups[1]))\n",
    "# # full_classifier.add_classifier(DoubleClassifier(depth[2],Groups[2]))\n",
    "# # full_classifier.add_classifier(DoubleClassifier(depth[3],Groups[3]))\n",
    "# # full_classifier.add_classifier(DecisionTreeClassifier(max_depth=depth[4]))\n",
    "# for ii in range(5):\n",
    "#         full_classifier.add_classifier(DecisionTreeClassifier(max_depth=depth[ii]))\n",
    "        \n",
    "# full_classifier.fit(x_train,y_train)\n",
    "# accuracy_step_3 = get_accuracy(x_test, y_test, snr_test, full_classifier,proxy_depth)\n",
    "# # label_detection(x_test, y_test, snr_test, f'Step Classification depth {total_depth}', full_classifier)\n",
    "# accuracy_data1,classifier = init_classification(samples, labels, snr, f\"Tree depth {total_depth}\", 1, total_depth)\n",
    "\n",
    "# combine_accuracy_graphs(accuracy_step_3,accuracy_data1)\n"
   ]
  },
 
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_list =[]\n",
    "for ii in range(4,10):\n",
    "    accuracy_data1,classifier = init_classification(samples, labels, snr, f\"Tree depth {ii}\", 5, ii)\n",
    "    acc_list.append(accuracy_data1)\n",
    "combo_graph(acc_list)\n",
    "combo_graph(acc_list,[8,30],[0.8,1])\n",
    "# acc_list2 = []\n",
    "# for ii in []:\n",
    "#     acc_list2.append(acc_list[ii])\n",
    "# combo_graph(acc_list2)\n",
    "\n",
    "# acc_list2 =[]\n",
    "# for jj in [-1,1,3,5,7,9,11,15]:\n",
    "#     accuracy_data1,classifier = init_classification(samples, labels, snr, f\"\", jj, 30)\n",
    "#     acc_list2.append(accuracy_data1)\n",
    "# combo_graph(acc_list2,[8,35],[0.98,0.99])\n",
    "# combo_graph(acc_list2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# deeps = [4,5,6,7,8,9]\n",
    "# with open('output.txt', 'w') as file:\n",
    "        \n",
    "#     for jj in range(10, 21):\n",
    "#         for ii in range(len(acc_list)):\n",
    "#             # Access the 'accuracy' and 'snr' values from the acc_list[ii] dictionary\n",
    "#             b = acc_list[ii]['accuracy'][jj]\n",
    "#             a = acc_list[ii]['snr'][jj]\n",
    "\n",
    "#             # Construct the output string\n",
    "#             output_str = f'Depth={deeps[ii]} ,Accuracy at {a}dB SNR = {b}\\n'\n",
    "\n",
    "#             # Write the output string to the file\n",
    "#             file.write(output_str)\n",
    "\n",
    "# # Notify the user that the data has been saved\n",
    "# print(\"Output data has been saved to 'output.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quick check for the double classifier\n",
    "\n",
    "# x_train, x_test, y_train, y_test, snr_test = threshold_split(samples,labels,snr)\n",
    "# # feat_bpsk_dsb = [2,4,9,10]\n",
    "# feat_bpsk_dsb = [0,2,4,6,7,9,10,11,12]\n",
    "# a = DoubleClassifier(6,['AM-DSB-SC','BPSK'])\n",
    "# a.fit(x_train,y_train,feat_bpsk_dsb)\n",
    "# y_predict = a.predict(x_test,feat_bpsk_dsb)\n",
    "\n",
    "# mask = np.isin(y_test,['AM-DSB-SC','BPSK'])\n",
    "# y_pair = y_test[mask]\n",
    "# y_pair_predict = y_predict[mask]\n",
    "# snr_pair = snr_test[mask]\n",
    "# unique_labels = ['AM-DSB-SC','BPSK','others']\n",
    "\n",
    "# for snr_val in [2,6,10,20,30]:\n",
    "#     mask_snr = snr_pair == snr_val\n",
    "#     y_pair_snr = y_pair[mask_snr]\n",
    "#     y_pair_predict_snr = y_pair_predict[mask_snr]\n",
    "#     accuracy_snr = accuracy_score(y_pair_snr, y_pair_predict_snr)\n",
    "#     cm = confusion_matrix(y_pair_snr, y_pair_predict_snr, labels=unique_labels)\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=unique_labels, yticklabels=unique_labels)\n",
    "#     plt.xlabel(\"Predicted Labels\")\n",
    "#     plt.ylabel(\"True Labels\")\n",
    "#     plt.title(f\"Confusion Matrix SNR={snr_val}dB, Acc={accuracy_snr}%\")\n",
    "#     file_path = f\"confusion_matrix_SNR={snr_val}.png\"\n",
    "#     plt.savefig(file_path)\n",
    "#     plt.clf()\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DNN classifier\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# model.add(layers.Dense(8, activation='relu'))\n",
    "# model.add(layers.Dense(np.unique(y_train).shape[0], activation='softmax'))\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=1, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
